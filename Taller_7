#Taller_7 Agrupación en el conjunto de datos del vehículo

#Descargar datos

!wget -O cars_clus.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cars_clus.csv
--2021-09-23 16:41:51--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cars_clus.csv
Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196
Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17774 (17K) [text/csv]
Saving to: ‘cars_clus.csv’

cars_clus.csv       100%[===================>]  17.36K  --.-KB/s    in 0s      

2021-09-23 16:41:53 (192 MB/s) - ‘cars_clus.csv’ saved [17774/17774]

#Leer los datos

import pandas as pd
filename = 'cars_clus.csv'
#Lectura
pdf = pd.read_csv(filename)
print ("Shape: ", pdf.shape)
pdf.head(5)

Shape:  (159, 16)
manufact	model	sales	resale	type	price	engine_s	horsepow	wheelbas	width	length	curb_wgt	fuel_cap	mpg	lnsales	partition
0	Acura	Integra	16.919	16.360	0.000	21.500	1.800	140.000	101.200	67.300	172.400	2.639	13.200	28.000	2.828	0.0
1	Acura	TL	39.384	19.875	0.000	28.400	3.200	225.000	108.100	70.300	192.900	3.517	17.200	25.000	3.673	0.0
2	Acura	CL	14.114	18.225	0.000	$null$	3.200	225.000	106.900	70.600	192.000	3.470	17.200	26.000	2.647	0.0
3	Acura	RL	8.588	29.725	0.000	42.000	3.500	210.000	114.600	71.400	196.600	3.850	18.000	22.000	2.150	0.0
4	Audi	A4	20.397	22.255	0.000	23.990	1.800	150.000	102.600	68.200	178.000	2.998	16.400	27.000	3.015	0.0

#Data cleaning

print ("Shape antes de cleaning: ", pdf.shape)
pdf[[ 'sales', 'resale', 'type', 'price', 'engine_s',
       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',
       'mpg', 'lnsales']] = pdf[['sales', 'resale', 'type', 'price', 'engine_s',
       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',
       'mpg', 'lnsales']].apply(pd.to_numeric, errors='coerce')
pdf = pdf.dropna()
pdf = pdf.reset_index(drop=True)
print ("Shape despues de cleaning: ", pdf.shape)
pdf.head(5)

Shape antes de cleaning:  (159, 16)
Shape despues de cleaning:  (117, 16)
manufact	model	sales	resale	type	price	engine_s	horsepow	wheelbas	width	length	curb_wgt	fuel_cap	mpg	lnsales	partition
0	Acura	Integra	16.919	16.360	0.0	21.50	1.8	140.0	101.2	67.3	172.4	2.639	13.2	28.0	2.828	0.0
1	Acura	TL	39.384	19.875	0.0	28.40	3.2	225.0	108.1	70.3	192.9	3.517	17.2	25.0	3.673	0.0
2	Acura	RL	8.588	29.725	0.0	42.00	3.5	210.0	114.6	71.4	196.6	3.850	18.0	22.0	2.150	0.0
3	Audi	A4	20.397	22.255	0.0	23.99	1.8	150.0	102.6	68.2	178.0	2.998	16.4	27.0	3.015	0.0
4	Audi	A6	18.780	23.555	0.0	33.95	2.8	200.0	108.7	76.1	192.0	3.561	18.5	22.0	2.933	0.0

1-Observando el proceso del codigo, que pueden concluir de que se realizo ?

pd.to_numeric: convierta un argumento en un tipo numérico, en donde errors='coerce' el análisis no válido se establecerá como NaN.
dropna(): se eliminaron los valores nulos (valores perdidos) del DataFrame dejando las filas o columnas
que contienen los valores nulos.
pdf.reset_index(drop=True): devuelve el nuevo DataFrame con información de etiquetado en las columnas debajo de los nombres de índice.
pdf.head(5): selecciona nuevamente cinco filas que cumplan las condiciones anteriores.

#Feature selection

2-Seleccionar las columnas engine_s, horsepow, wheelbas, width, lenght, curb_wgt, fuel_cap y mpg y guardarlas en el dataset featureset

feature_set = pdf[[ 'engine_s', 'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']]
print(feature_set)
feature_set.head(5)

 engine_s  horsepow  wheelbas  width  length  curb_wgt  fuel_cap   mpg
0         1.8     140.0     101.2   67.3   172.4     2.639      13.2  28.0
1         3.2     225.0     108.1   70.3   192.9     3.517      17.2  25.0
2         3.5     210.0     114.6   71.4   196.6     3.850      18.0  22.0
3         1.8     150.0     102.6   68.2   178.0     2.998      16.4  27.0
4         2.8     200.0     108.7   76.1   192.0     3.561      18.5  22.0
..        ...       ...       ...    ...     ...       ...       ...   ...
112       2.0     115.0      98.9   68.3   163.3     2.767      14.5  26.0
113       2.0     115.0      98.9   68.3   172.3     2.853      14.5  26.0
114       1.8     150.0     106.4   68.5   184.1     3.043      16.4  27.0
115       2.0     115.0      97.4   66.7   160.4     3.079      13.7  26.0
116       2.0     115.0      98.9   68.3   163.3     2.762      14.6  26.0

[117 rows x 8 columns]
engine_s	horsepow	wheelbas	width	length	curb_wgt	fuel_cap	mpg
0	1.8	140.0	101.2	67.3	172.4	2.639	13.2	28.0
1	3.2	225.0	108.1	70.3	192.9	3.517	17.2	25.0
2	3.5	210.0	114.6	71.4	196.6	3.850	18.0	22.0
3	1.8	150.0	102.6	68.2	178.0	2.998	16.4	27.0
4	2.8	200.0	108.7	76.1	192.0	3.561	18.5	22.0

#Clustering usando SCIpy

3-En esta parte usamos el paquete Scipy para agrupar el conjunto de datos: Primero, calculamos la matriz de distancias.
Convertir a una matriz de distancias el dataset feature_set utilizando la funcion featureset.values y guardar el resultado en feature_mtx

feature_mtx = pairwise_distances(
                X      = feature_set.values,
                metric ='euclidean'
             )

print(feature_mtx)

[[  0.          87.9180919   75.79845989 ...  16.63650252  28.07638866
   26.83496095]
 [ 87.9180919    0.          17.0877409  ...  75.60022934 115.3194773
  114.3440861 ]
 [ 75.79845989  17.0877409    0.         ...  62.15304698 103.39586278
  102.0832197 ]
 ...
 [ 16.63650252  75.60022934  62.15304698 ...   0.          43.35044747
   41.45224917]
 [ 28.07638866 115.3194773  103.39586278 ...  43.35044747   0.
    3.75905427]
 [ 26.83496095 114.3440861  102.0832197  ...  41.45224917   3.75905427
    0.        ]]

Si todo marcha en orden no deberia haber problemas con los siguientes dos segmentos de código

import scipy
leng = feature_mtx.shape[0]
D = scipy.zeros([leng,leng])
#D = numpy.zeros([leng,leng])
for i in range(leng):
    for j in range(leng):
        D[i,j] = scipy.spatial.distance.euclidean(feature_mtx[i], feature_mtx[j])
/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: scipy.zeros is deprecated and will be removed in SciPy 2.0.0, use numpy.zeros instead
  This is separate from the ipykernel package so we can avoid doing imports until
 
import scipy
leng = feature_mtx.shape[0]
#D = scipy.zeros([leng,leng])
D = numpy.zeros([leng,leng])
for i in range(leng):
    for j in range(leng):
        D[i,j] = scipy.spatial.distance.euclidean(feature_mtx[i], feature_mtx[j])

D
array([[  0.        , 695.54964914, 617.88099439, ..., 133.886184  ,
        263.78206235, 251.57343468],
       [695.54964914,   0.        , 139.08404576, ..., 632.05912691,
        817.38327764, 818.30048259],
       [617.88099439, 139.08404576,   0.        , ..., 539.79383871,
        768.9540551 , 767.44939952],
       ...,
       [133.886184  , 632.05912691, 539.79383871, ...,   0.        ,
        384.76326673, 373.49300085],
       [263.78206235, 817.38327764, 768.9540551 , ..., 384.76326673,
          0.        ,  19.99239837],
       [251.57343468, 818.30048259, 767.44939952, ..., 373.49300085,
         19.99239837,   0.        ]])
  
4-Utilizaremos complete para nuestro caso, pero en una proxima oportunidad siéntanse libres de cambiarlo para ver cómo cambian los resultados.

import pylab
import scipy.cluster.hierarchy
z=scipy.cluster.hierachy.linkage(D,'complete')

Calcular el objeto Z por medio de la siguiente estructura de código:






